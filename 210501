
11주차 9장 구간추정1
11주차 9장 구간추정2
11주차 9장 구간추정3

12주차 10장 가설검정1
12주차 10장 가설검정2
12주차 10장 가설검정3

13주차 10장 가설검정4
13주차 11장 범주형자료분석1
13주차 11장 범주형자료분석2

14주차 회귀분석1
14주차 회귀분석2
14주차 분산분석1


===================================================


http://matrix.skku.ac.kr/knou-knowls/

11주차 주성분 분석 1
11주차 주성분 분석 2

12주차 LDA
12주차 LoR

13주차 linear-svm
13주차 nonlinear-svm

14주차 최적화 기초
14주차
14주차


===================================================

11주차 온라인 수업-1차시(해시테이블-선형조사&이차조사)
11주차 온라인 수업-2차시(이중해싱&체이닝)
11주차 온라인 수업-3차시(과제설명&선택정렬)

12주차 온라인 수업-1차시(기본정렬&쉘정렬)
12주차 온라인 수업-2차시(쉘&힙&병합)
12주차 온라인 수업-3차시(병합&퀵&기수정렬)

13주차 온라인 수업-1차시(기수정렬&그래프구조)
13주차 온라인 수업-2차시(그래프탐색)
13주차 온라인 수업-3차시(위상정렬&연결성분)

14주차
14주차
14주차

===================================================


음향테스트
https://www.audiocheck.net/

파이선 RT60 값 분석 (librosa)
https://ahnjg.tistory.com/83?category=1135285
https://start-up.house/en/blog/articles/reverberation-time-sound-analysis-python
https://lucaseo.github.io/posts/2021-01-22-hands-on-preprocess-audio-data/
https://m.blog.naver.com/PostView.nhn?blogId=cassiopeia84&logNo=40202107686&proxyReferer=https:%2F%2Fwww.google.com%2F

https://mac.kaist.ac.kr/~juhan/gct634/
https://librosa.org/doc/latest/advanced.html#advanced

음성인식
https://newsight.tistory.com/294
https://seungheondoh.netlify.app/blog/fft


음향학 기초
http://contents.kocw.net/KOCW/document/2015/pusan/kwonsoonbok/9.pdf

===================================================


from scipy.io import wavfile
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy import stats

# 파일 경로 지정 (WAV 확장자 주의)
sample_rate,data = wavfile.read('C:/Users/user/Documents/Audacity/210517_test (linear)(0)_normal_mic2.wav')

amount_of_samples = len(data)
length_of_sound = amount_of_samples / sample_rate
print("Amplitude data:",data)
print("샘플링 레이트:",sample_rate)
print("총 샘플 수:",amount_of_samples)
print("파일 길이(S)",length_of_sound)

# 추출한 데이터 (signal 값) signal_data 객체에 저장
signal_data = data
# - 1 TO 1 로 변환 시키기  (Scaled_data) (16bit 기준)
scaled_data = data / 2.**15
# np.array 함수 사용 (처음,마지막,간격)
time_array = np.arange(0,float(amount_of_samples),1)/sample_rate

#plt.plot 함수(x,y)
plt.plot(time_array,scaled_data,linewidth = 0.3 , alpha = 0.7 , color ="#004bc6")
plt.title("Mic raw data(WAV)")
plt.xlabel("time(s)")
plt.ylabel("amplitude")

plt.show()

# index / freq = time
# signal data가 max 일때의 인덱스값 저장 argmax 함수
# max 일때의 value 값은 인덱스에 저장
index_of_raw_max = np.argmax(signal_data)
value_of_raw_max = signal_data[index_of_raw_max]

#min 값일때 index 저장 / value 저장
index_of_raw_min = np.argmin(signal_data)
value_of_raw_min = signal_data[index_of_raw_min]

"""
# 시그널 데이터 맥스값에서 비율 조정 where 함수
index_of_raw_max_10 = np.where(signal_data > value_of_raw_max // 10)[0][0]
index_of_raw_max_25 = np.where(signal_data > value_of_raw_max // 4)[0][0]
index_of_raw_max_50 = np.where(signal_data > value_of_raw_max // 2)[0][0]
index_of_raw_max_75 = np.where(signal_data > (value_of_raw_max // 4) * 3)[0][0]

value_of_raw_max_25 = signal_data[index_of_raw_max_25]
value_of_raw_max_50 = signal_data[index_of_raw_max_50]
value_of_raw_max_75 = signal_data[index_of_raw_max_75]
"""

"""
print("max값:",value_of_raw_max)
print("max index:" ,index_of_raw_max)
print('max time 10%:',index_of_raw_max_10/16000)
print('max time 25%:',index_of_raw_max_25/16000)
print('max time 50%:',index_of_raw_max_50/16000)
print('max time 75%:',index_of_raw_max_75/16000)
print('max time:',index_of_raw_max/16000)
print('min time:',index_of_raw_min/16000)
"""


# 시그널 값 저장
# data 획득 및 저장 dataframe / to_csv
mic_signal_table = pd.DataFrame(data=signal_data)
print("시그널 데이터 모양",mic_signal_table.shape)
mic_signal_table.to_csv('C:/Users/user/Documents/Audacity/210517_test (linear)(0)_normal_mic2___amplitude.csv')



# matplotlib.pyplot.specgram : https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.specgram.html
# data : array / FS : sampling time / NFFT : The number of data points used in each block for the FFT. A power 2 is most efficient. / Cmap : color map)
# 이론적 배경 : https://sanghyu.tistory.com/37?category=1120070 
spectrum,freqs,t,im = plt.specgram(data,Fs=sample_rate,NFFT=1024,cmap=plt.get_cmap('autumn_r'))
cbar = plt.colorbar(im)

plt.title("Fourier transform")
plt.xlabel('time(s)')
plt.ylabel('frequency(Hz)')
cbar.set_label("intensity(dB)")

plt.show()

# Fourier Transform 한 주파수 (Freqs Spectrum) data dB 변경
index_of_frequency = np.where(freqs==250)[0][0]
data_for_frequency = spectrum[index_of_frequency]
data_in_db = 10 * np.log10(data_for_frequency)
plt.plot(t,data_in_db,linewidth =1,alpha=0.7,color='#004bc6')
plt.title("Time(s) - dB")
plt.xlabel('time(s)')
plt.ylabel('power(dB)')
plt.show()


# data 획득 및 저장 dataframe / to_csv (DB값 저장)
data_in_db_table = pd.DataFrame(data=data_in_db)
print("DB 데이터 모양",data_in_db_table.shape)
data_in_db_table.to_csv('C:/Users/user/Documents/Audacity/210517_test (linear)(0)_normal_mic2___DB.csv')




index_of_max = np.argmax(data_in_db)
value_of_max = data_in_db[index_of_max]
# plt.plot 추가
plt.plot(t[index_of_max],data_in_db[index_of_max],'go')

sliced_array = data_in_db[index_of_max:]

# max value 에서 -5 dB 값 저장
value_of_max_less_5 = value_of_max - 5
def find_index(array, value):
    array = np.asarray(array)
    idx = (np.abs(array-value)).argmin()
    return array[idx]


value_of_max_less_5 = find_index(sliced_array, value_of_max_less_5)
index_of_max_less_5 = np.where(data_in_db == value_of_max_less_5)

plt.plot(t[index_of_max_less_5],data_in_db[index_of_max_less_5],'yo')

value_of_max_less_25 = value_of_max - 25
value_of_max_less_25 = find_index(sliced_array, value_of_max_less_25)
index_of_max_less_25 = np.where(data_in_db == value_of_max_less_25)

plt.plot(t[index_of_max_less_5],data_in_db[index_of_max_less_25],'ro')
plt.plot(t,data_in_db,linewidth =1,alpha=0.7,color='#004bc6')
plt.title("dB")
plt.xlabel('time(s)')
plt.ylabel('power(dB)')
"""
plt.show()
"""


value_of_max_less_35 = value_of_max - 35
value_of_max_less_35 = find_index(sliced_array, value_of_max_less_35)
index_of_max_less_35 = np.where(data_in_db == value_of_max_less_35)[0][0]


# slope 를 그리기 위한 index 지정 (-35dB)
x = t[index_of_max: index_of_max_less_35]
y = data_in_db[index_of_max: index_of_max_less_35]

slope,intercept,r_value,p_value,std_err = stats.linregress(x,y)
linregress = intercept + slope * x
plt.plot(t,data_in_db,linewidth =1,alpha=0.7,color='#004bc6')
plt.title("linear regression")
plt.xlabel('time(s)')
plt.ylabel('power(dB)')
"""
plt.show()
"""

rt20 = (t[index_of_max_less_5]-t[index_of_max_less_25])[0]
rt30 = (t[index_of_max_less_5]-t[index_of_max_less_35])[0]
rt60 = 3 * rt20

print(abs(rt20))
print(abs(rt30))



"""
value_of_max_less_60 = value_of_max - 60
value_of_max_less_60 = find_index(sliced_array, value_of_max_less_60)
index_of_max_less_60 = np.where(data_in_db == value_of_max_less_60)[0][0]

x = t[index_of_max: index_of_max_less_60]
y = data_in_db[index_of_max: index_of_max_less_60]

slope,intercept,r_value,p_value,std_err = stats.linregress(x,y)
plt.plot(x, intercept + slope * x , 'r' , label = 'linear regression')
linregress = intercept + slope * x
plt.plot(t,data_in_db,linewidth =1,alpha=0.7,color='#004bc6')
plt.show()
"""

===================================================


import pandas as pd
import numpy as np
from scipy.io import wavfile
import librosa.display
import matplotlib.pyplot as plt
import math

# 음성 파일 로딩
file = 'C:/Users/user/Documents/Audacity/210512 test(mic1).wav'
# Signal , Sampling rate 설정
signal, sample_rate = librosa.load(file, sr=16000)

# signal벡터 갯수 분석
print("Signal Amplitude data:",signal)
print("Sample size:",signal.shape)

# Waveform 형태 분석
fig = plt.figure(figsize =(14,5))
librosa.display.waveplot(signal,sr=sample_rate)
plt.ylabel("Amplitude")
plt.xlabel("time(s)")
plt.show()

#출력한 waveform data 획득 및 저장
mic_signal_table = pd.DataFrame(data=signal)
print(mic_signal_table.shape)
mic_signal_table.to_csv('C:/Users/user/Documents/Audacity/saved_mic_wav_16Khz.csv')

"""
#출력한 Wavform data DB 획득 및 저장 ( dB = 20 * log10(amplitude / (1/sampling rate*2 ) ) (dB = 20 * log10(A/A0)) (ex 8 bit = -128 to 127)
signal_to_db = 20 * np.log10(signal)
mic_signal_to_db_table = pd.DataFrame(data=signal_to_db)
print(mic_signal_table.shape)
mic_signal_table.to_csv('C:/Users/user/Documents/Audacity/saved_mic_wav_16Khz_dB.csv')

"""

"""
# FFT 실행
# 샘플 hop 넘버 / 샘플 윈도우 수
hop_length = 512
n_fft = 2048

# duration 계산
hop_length_duration = float(hop_length)/sample_rate
n_fft_duration = float(n_fft)/sample_rate

# STFT 실행
stft = librosa.stft(signal,n_fft=n_fft,hop_length = hop_length)
print("stft shape:",stft.shape)

# Spectrogram 생성
spectrogram = np.abs(stft)
print("spectrogram shape:",spectrogram.shape)

# display spectrogram
plt.figure(figsize=(14,5))
librosa.display.specshow(spectrogram,sr=sample_rate,hop_length=hop_length)
plt.xlabel("Time(s)")
plt.ylabel("Frequency")
plt.colorbar()
plt.title("Spectorgram")
plt.show()

# calcurate Amplitude to Decibel (Using Spectrogram)
log_spectrogram = librosa.amplitude_to_db(spectrogram)
print("log spectrogram shpae",log_spectrogram.shape)
plt.figure(figsize=(14,5))
librosa.display.specshow(log_spectrogram,sr=sample_rate,hop_length=hop_length)
plt.xlabel("time(s)")
plt.ylabel("Frequency")
plt.colorbar(format = "%+2.0f dB")
plt.title("Spectrogram *dB")
plt.show()
"""

===================================================


컴퓨터 관련 
https://namu.wiki/w/%EC%BB%B4%ED%93%A8%ED%84%B0%20%EA%B4%80%EB%A0%A8%20%EC%A0%95%EB%B3%B4#rfn-7 


회로설계
블록다이어그램 -> 회로도(스캐매틱) -> 아트웍 -> BOM -> 발주  
https://kernel.bz/blogPost/bombee_sch

대출규제
대출규제 발표 


세계의 요리
https://namu.wiki/w/%ED%8B%80:%EC%84%B8%EA%B3%84%EC%9D%98%20%EC%9A%94%EB%A6%AC


용과같이극7
https://konsoler.com/g2/bbs/board.php?bo_table=game_5_1&wr_id=31


사울왕조 다윗왕조 
https://namu.wiki/w/%EB%8B%A4%EC%9C%97


=====================================


# https://wikidocs.net/14646

import matplotlib.pyplot as plt
import numpy as np
# 3차원 그래프 from mpl_toolkits.mplot3d import Axes3D를 추가해줍니다.
from mpl_toolkits.mplot3d import Axes3D

# x,y,z 생성
x = [0 ,10]
y = [0, 10]
z = [0, 10]

# figure 크기 설정
# fig = plt.figure()만 사용해도 됨.
fig = plt.figure(figsize=(10, 10))

# 3D axes를 만들기 위해 projection=’3d’ 키워드를 입력해줍니다.
# GCA = get current axes 
ax = fig.gca(projection='3d')

# scatter() 함수에 준비된 x, y, z 배열 값을 입력해주고
# 마커, 스타일 및 마커 색상 등을 설정할 수 있습니다.
# marker = 점의 형태
# s = 점의 크기
# c = 점의 색깔
ax.scatter(x, y, z, marker='o', s=0.1, c='darkgreen')
ax.scatter(3,4,5, marker='o',s=20, c='darkgreen')
ax.scatter(7,4,5, marker='o',s=20, c='darkgreen')



plt.show()

# x2 + y2 + z2 = root c 인 x,y,z 그래프 그리기
# 정육면체 이므로 = 함수 6개 가능 (어려움 포기) (...)



=====================================


머리전달함수

① 양쪽 귀에 도달하는 소리의 시간차 (ITD; Interaural Time Difference)
② 양쪽 귀에 도달하는 소리의 세기차 (IID; Interaural Intensity Difference)

 필터링에 의해 입체음을 생성하는 방법
머리 전달 함수(HRTF)를 이용하여 음상 정위를 생성하고, 공간 전달 함수(RTF)를 이용하여 특정 장소에 대한 공간감을 생성한다.
 
(1) 머리 전달 함수(HTRF: Head-Related Transfer Function)를 이용
무향실 내에서 Dummy Head의 양쪽 귀에 마이크로폰을 설치하고 여러 각도로 배치된 스피커에서 나오는 음(White Noise)들을 녹음하여 
푸리에(Fourier) 변환함으로써, 음의 위치에 따라 양쪽 귀에 들리는 소리의 주파수별 특성을 구할 수 있다. 
머리 전달 함수는 소리가 들어오는 각도에 따라 달라지기 때문에 여러 위치에서 나오는 
음들에 대해 머리 전달 함수를 측정하고 이를 데이터베이스로 구축하는 것이 필요하다.
 
(2) 공간 전달 함수(RTF: Room Transfer Function)
특정 장소에 따른 공간의 크기, 구조, 벽 또는 천정 재질 등에 의해 
음원에 대한 직접음, 초기 반사음, 잔향 패턴 및 잔향 시간 등이 달라진다. 
특정 장소의 효과를 생성하기 위해서는 무향실이 아닌 특정 실내에서 머리 전달 함수를 측정해야 한다. 
특정한 장소에서 측정한 머리 전달 함수를 공간 전달 함수라고 한다. 
이를 이용하여 특정한 장소에 대한 가상의 음장(음원을 둘러싸고 있는 공간)을 생성할 수 있다.
