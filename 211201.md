# 새로 익히기 개요

### 컴퓨터 비전
		
+ Segmentation & Clustering
	+ Morphological operation
	+ Clustering as segmentation
	+ Graph based clustering
	+ Fitting

+ Classification
	+ Bag of Features
		+ https://darkpgmr.tistory.com/125 
		+  기하학적인 관계를 정확하게 매칭하는 방법(homography를 이용한 SIFT 매칭
		+  bag of words 기법을 이용하여 feature들의 히스토그램을 매칭하는 방법

	+ Classifier
		+ K-Nearest Neighbor
		+ Naïve Bayes
		+ Support Vector Machine

+ Classification & Network
	+ Convolution Networks 
	+ Neural Networks
	+ Convolutional NN 

+ Two-view Geometry
	+ Epipolar Geometry
	+ Essential matrix
	+ Fundamental matrix

+ Stereo Vision
	+ Stereo Rectification
	+ Stereo Matching
	+ Disparity & Depth

+ Motion Tracking
	+ Motion
	+ Optical Flow   
		+ Lucas-Kanade
		+ Horn-Schunck
	+ Visual Tracking
		+ Kanade-Lucas-Tomasi
		+ Mean shift tracking
		+ Cam shift tracking

+ Robot Vision
	+ CV vs. MV vs. RV
	+ Visual Servoing
	+ Visual SLAM


### 자연어처리 


+ 형태소 분석 (HMM 기반)
	+ Basic Probability Theory / Estimating Probability
	
	+ POS Tagging 
		+ Language Model(1) - Bayesian Theorem 부터 Naive Bayes까지
		+ https://www.quantumdl.com/entry/Language-Model-Naive-Bayes?category=691797 
		+ Language Model(2) - HMM을 이용한 Part of Speech(POS) Tagging
		+ https://www.quantumdl.com/entry/Language-Model2-HMM%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-Part-of-SpeechPOS-Tagging
	
	+ Forward and Backward Algorithm
		+ [Algorithms for NLP] POS tagging, HMM, Viterbi
		+ https://m.blog.naver.com/ckdgus1433/221812095900 
	
+ 워드임베딩 (Word Embedding)
	+ Basic idea of learning neural network word embeddings 
		
	+ Approaches for Word Embedding
		+ Ranking-based
		+ [논문 요약 2018-07] Improving Negative Sampling for Word Representation using Self-embedded Features
		+ https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=hist0134&logNo=221218233489
		
		+ Word2Vec 
		+ Word2Vec (1) : 단어 임베딩 & CBOW 모델
		+ https://reniew.github.io/21/
		
		+ Word2Vec (2) : Skip Gram 모델 & 튜닝 기법
		+ https://reniew.github.io/22/ 	
		
		+ Glove  
		+ https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/09/glove/

+ 딥러닝 기반의 자연어처리 모델 (RNN)
	+ Convolutional Neural Networks
	
	+ Learning Representation for NLP
		+ Deep Learning, NLP, 그리고 Representation
		+ https://dgkim5360.tistory.com/entry/deep-learning-nlp-and-representations-kr 

	+ Recurrent Neural Networks (LSTM,GRU)
		+ Gated Recurrent Units
		+ Long Short-Term Memory (이해하기) 
		+ https://dgkim5360.tistory.com/entry/understanding-long-short-term-memory-lstm-kr?category=912687
	
	
+ 딥러닝 기반의 자연어처리 모델 (Attention)
	+ Attention Mechanism
		+ 먼 거리에 위치한 단어의 가중치를 현재 단어에 효과적으로 반영할 수 있는 방법이 없을까? 
		+ Attention 구조는 각 입력이 출력 상태에 연결 신경망 추가 (모든 단어들의 가중치)
		+ Transformer - Harder, Better, Faster, Stronger
		+ https://blog.pingpong.us/transformer-review/
	

+ 더 나아간 모델들?
	+ Introduction to Pre-trained Language Representations
		+ (Feature-based approach) ELMo
		+ (Fine-tuning approach) OpenAI GPT
		+ (Fine-tuning approach) BERT
		+ Various Types of BERT (RoBerta, Albert) 
		+ T5
			+ Exploring Transfer Learning with T5 : the Text-To-Text Transfer Transformer (1)
			+ Exploring Transfer Learning with T5 : the Text-To-Text Transfer Transformer (2)
			+	https://soundprovider.tistory.com/entry/Exploring-Transfer-Learning-with-T5-the-Text-To-Text-Transfer-Transformer-2?category=1126750

### 자연어처리 Pipeline

+ NLP PipeLine
	+ NLP의 작업 과정 
	+ https://www.quantumdl.com/entry/NLP%EC%9D%98-%EC%9E%91%EC%97%85-%EA%B3%BC%EC%A0%95?category=691797 


+ 워드 임베딩 (Feature Extraction) 

+ 언어 모델 : 다음 문장이 적합한지 컴퓨터가 확률을 계산하는 것

	+ https://wikidocs.net/21668 
	+ 통계모형 
		+	https://wikidocs.net/21687 
	+ 인공 신경망 모형
		+ https://wikidocs.net/46496
	
+ Train Model : 
	
	+ LSTM , GRU 

+ Attention Model : 
	+ BERT
		+ https://simonezz.tistory.com/48?category=892980 

	+ OpenAI GPT-1	
		+  https://simonezz.tistory.com/73?category=892980
	
	+ ELMO (Pre_train_model)
		+ https://wikidocs.net/33793


### 머신러닝

+ Genetic Algorithm

+ NN
	+ from keras.datasets import mnist 
	+ from keras.datasets import imdb
	+ from keras.datasets import reuters
	+ from keras.datasets import boston_housing 

# 새로 찾기 

### 데이터셋 선정

+ GAN 
	+ 데이터셋 구축에서 GAN의 중요성  
	+ https://blog.testworks.co.kr/importance_of_gan_in_ai_dataset_building/ 

### 모델 선정

+ GAN / U-net
	+ [Review] A U-Net Based Discriminator for Generative Adversarial Networks
	+ https://cdm98.tistory.com/55 

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FuZUB5%2FbtqWc9hqqIj%2FkPQJ75BN5diCYhCvAN3hk1%2Fimg.png)
+ AutoEncoder (1) : Maximum likelihood 관점에서의 해석
	+ https://junstar92.tistory.com/156?category=905977

### 최적화 

+ 최적화 기법의 직관적 이해
	+ https://darkpgmr.tistory.com/149
+ 함수최적화 기법 정리
	+ https://darkpgmr.tistory.com/142
 
### 추론

+ 딥러닝 모델 서비스 A-Z 1편 - 연산 최적화 및 모델 경량화
	+ https://blog.pingpong.us/ml-model-optimize/

