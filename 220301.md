

---

# 기계학습론

+ Linear Model 
  + Scratch
  + Function : MSE (Mean square error) 
    + 매개변수 W 규제 : L1 (Lasso - on/off) vs L2 norm (Ridge - )   
  
+ KNN
  + Scratch
  + Fuction : Regression (Value) vs Classification (Distance)
    + No training (Only inference) 

+ logistic classification(Binary)
  + Scratch
  + Function : p/1-p  

+ Naïve Bayesian 
  + Scratch (NPL) 
  + Fuction : Conditional Probability
    + https://ratsgo.github.io/machine%20learning/2017/05/18/naive/
  
+ Decision Tree
  + Scratch 
  + Node Prunning 
  + Function : Gini / Entropy Gain (Cross Entropy) 
    + 좋은 분류기? 데이터의 분할을 통해 데이터가 가진 정보들의 불확실성(엔트로피)를 계속해서 줄여나가는것 
    + 엔트로피값의 차이를 계산 (Gain)

+ Random Forest
  + Scratch
    + Function : bagging(Bootstrap aggregation) training 
  
+ SVM
  + Scratch 
  + Function : SVM hinge Loss (like 1 layer perceptron : (Wx + b)  + hinge loss) 
    + https://github.com/ExcelsiorCJH/Hands-On-ML/blob/master/Chap05-SVM/Chap05-SVM.ipynb
  + Multi-class classification 학습 : (softmax / Cross entropy loss) vs SVM ? Hinge loss
    + https://younnggsuk.github.io/2020/12/03/cs231n-3.html

+ Clustering
  + Kmeans
    + how to K ?  
    + Function : Centering K with Distrance of data

+ Dimenstion 
  + PCA 
    + XX(transpose) = Feature covar matrix & eigen value / Vector   
 
+ Loss Function 
  + https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23
 
---

# 딥러닝

##### Machine Learning Basics

+ 주어진 데이터와 에러를 최소하는 함수를 찾자! 

+ 회귀분석 모형
  + 에러를 최소화 하는 매개변수 W 찾기  
  + 에러 함수 : MSE (Mean square error)
  + 방정식 : 매개변수(W) N개에 대해 N개의 미분방정식
  + 근사 : SGD 방법 
    + (데이터가 추가될 때마다 미분식을 계속 만든다..? Nope 일반 미분식에 data를 추가하여 보정) 

##### Neural Networks 

+ 퍼셉트론 구조 
  + 퍼셉트론 : 스위치 / 의사결정 
    + 스위치 : Activation function
  + (AND or OR GATE: 스위치 to 논리회로 구성) (스위치 Connection Weight 설정) 
  + XOR 문제 해결 : (by layer)
    + Connection Weight 를 어떤식으로 자동 설정 (=학습) 해줄 것 인가? 

+ 퍼셉트론 모델  
  + 매개변수 W1,W2,W3,...Wn  
  + perceptron exercise pdf (http://www.mmds.org/)
    + 퍼셉트론 모델 기초 W0 + W1X1 +.... + WnXn
  
+ 퍼셉트론 모델 학습 
  + WEIGHT TRAINING IN A PERCEPTRON 
  + Forward loop / backward loop 
    + 포워드 + 백워드 (백워드는 미분식 연쇄)

+ 이진분류 / 다중분류 / . . .함수 선택
  + Hidden layer function  : Relu
    + why ? Sigmoid : Gradient Vanishing  
  + Activation function  : linear(target value) / sigmoid(binary classification) / softmax (multi)
  + loss function : MSE (target Regression) or C.E(probs Classification) 
    + 예시? multi class CE : sum ( -(target) * log P ) 
    + One hot encoding (1 0 0 0 0 ) + Probs (1/5 1/5 1/5 1/5 1/5) & Cross entorpy 로 측정가능 

+ 기울기소실 / 학습이 잘 안될때 개선을 위한 노력?
  + 전달 함수 (Activa Function) 변경 : Relu 
  + 손실 함수 (Loss function) : Gradient Descendant 방법 변경 : ADAM 
  + Batch Normalization
  + Dropout
  + https://ratsgo.github.io/deep%20learning/2017/04/22/NNtricks/

---

# 고급 딥러닝 

+ 2주차 
+ KMeans (클러스터링)
  + 클러스터링 정량화 : 거리표현 (유클리디안,맨하탄..)
  + KMeans : k 클러스터 중심과 데이터의 거리 계산 (sklearn)

+ 3주차
  + 나이브 베이지안 
    + P(A) : 사전확률 
    + P(A|B) : 사후확률
    + P(B) : 증거 (추가된 정보)
    + P(B|A) : 가능도 (likelihood)

  + 사이킷런 데이터 API
    + https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets 

+ 4주차
  + 정확도와 정밀도

+ 5주차
  + SVM 

+ HW1
  + https://books.google.co.kr/books?id=pgyLDwAAQBAJ&pg=PA116&lpg=PA116&dq=naive-bayes-from-scratch+enron&source=bl&ots=ZdTUQAMWmd&sig=ACfU3U2lXgnGibZyoRkMh-3erUCEKlQK_Q&hl=ko&sa=X&ved=2ahUKEwifyY-O4eD2AhU4y4sBHaHpCdkQ6AF6BAgdEAM#v=onepage&q=naive-bayes-from-scratch%20enron&f=true 

  + python machine learning by example yuxi liu pdf

+ 6주차
  + Decision Tree 

+ WH2 
  + https://colab.research.google.com/github/akshayrb22/playing-with-data/blob/master/supervised_learning/support_vector_machine/svm.ipynb#scrollTo=6Ah0pRVPoLYt 
--

# 자연어처리 기초 
+ NLP Basic
  + NLTK 말뭉치 : 코퍼스 (Corpus)
  + 토큰화 : (ex 유니/바이/트라이그램...)
  + 품사태깅 (pos_tag(input_token)) 
  + NER -  카테고리 지정 (ex 성균관대학교 - 대학교)
  + 어간추출 Stemming - 원래 어근 추출 
  + 표제어 원형 복원 lemmatizer - 표제어 복원(명사원형)   

+ 텍스트 분석 
  + 단어 위주
  + 단어의 출연여부 / 빈도 / 문서 전체 고려 TF IDF 가중치
  + Bag of Word 단어들의 뭉치 

+ 데이터 준비 newgroup20
  + 기사 데이터셋 확보 (sklearn) 

+ 데이터 비주얼라이제이션
  + 데이터의 구조적 특징 분석  
  + seaborn . matplotlib
  + CountVectorizer 활용 : 상위 500개 빈도 출력?!
  + seaborn 을 이용한 상위 500개 빈도수 그래프화   

+ 텍스트 전처리
  + NER / 어간추출/ 표제어 ... 데이터 중복이나 무의미 데이터 삭제 (노이즈 제거) 

---

# X-ray (LGE) 



---

# 알고리즘 

---

# Scratch

+ 머신러닝 알고리즘 구현
  + naive bayes
    + https://zephyrus1111.tistory.com/80  
  + SVM
  + logisitic regression
  + KNN
    + https://zephyrus1111.tistory.com/77?category=858748 
    + https://github.com/mavaladezt/kNN-from-Scratch 
  + Kmeans  

+ 논문 딥러닝 구현 
  + https://github.com/Seonghoon-Yu/AI_Paper_Review


---

# 기타 

+ 사이킷런
  + https://scikit-learn.org/stable/

+ 파이토치
  + https://pytorch.kr/

+ 파이선 스니펫 

+ 알고리즘 

+ 논문 ACM Template
  + https://www.acm.org/publications/proceedings-template


---

# TEST

https://lgehq.webex.com/lgehq/e.php?MTID=mfc3dbfa6c17be44b9758e4f229309d46


---
