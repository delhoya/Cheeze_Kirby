
# 새로 익히기

+ KNN / SMOTE
+ linear regression / logistic regression matrix form
+ SVM

+ 나이브 베이지안
+ 히든 마코프 체인

+ 엔트로피
+ 크로스 엔트로피
+ KL Divergence



# 파이선


# 알고리즘 


# 컴퓨터 비전

5주차 - 9/27(월)

+ detect/extract features
  + Edge detection
    + using derivatives (image gradient)
    + Prewitt operator, Sobel operator
  + Line detection
    + using edge detection & non-maximum suppression 
    + Canny operator, Hough Transform
  + Corner detection
    + using a large change of intensity in any direction (significant change in all directions)
      + H matrix from the entries in the gradient (eigenvector)
    + Harris detector 
  + Blob detection
    + Finding characteristic region size (Laplacian of Gaussian looks bit like blob)
    + Laplacian of Gaussian
    
# 자연어 처리 

5주차 - 9/27(월)

+ Stochastic Sequence Labeling
  + 1. 통계기법이 자연어 처리에서 활용되는 방법? Markov chain - 마르코프 체인
  + 2. 시퀀스 레이블 HMM   - 은닉 마르코프 모델 

+ Single classification vs sequential classifiacation 
  + 물고기 사진 검사 vs 단어의 순서적 배열의 적절성 평가? and 예측? 

+ Pattern recognition /  classification 모델 2가지 분류가능 (+ Generative vs Discriminate model )
  + https://sens.tistory.com/408 
  + P(Y|X) : X가 주어졌을때 Y (Class) 의 classification 
    + 1. P(X|Y) and P(Y) 이용하여 학습 -> P(Y|X) (Generative)  
      + ex) 나이브베이지안,HMM 
    + 2. P(Y|X) 를 바로 찾으려는 시도 (Discriminate model) - 확률 구하기가 힘드니까 Score 로 .. 
      + ex)MEM CRF(conditional random field) SVM DNN

+ 나이브 베이지안 
  + Single classification 
  + 
  
+ HMM
  + Sequential  
  +
  
# 머신 러닝 모형

+ KNN (K-Nearest Neighbor)
  + SMOTE(synthetic minority oversampling technique) / (for data agumentation)
  + https://wordbe.tistory.com/entry/GAN-Data-Augmentation-Using-GANs-2019
  + https://www.kaggle.com/qianchao/smote-with-imbalance-data

5주차 - 9/27(월)
+ SVM (Support vector machine) + Kernel 


# 선형대수학 

+ Linear regression matrix form
  + 행렬 연산 추가 
  + 적용하기 
    + https://yganalyst.github.io/ml/ML_chap3-1/ 
  + 수학적증명
    + https://jangpiano-science.tistory.com/111 
  
+ SVM 
  + 적용하기
    + https://hleecaster.com/ml-svm-concept/
  + 수학적 증명
    + https://ratsgo.github.io/machine%20learning/2017/05/23/SVM/ 
  
+ Edge detection 
  +   (Gradient 변화 극대?)
  + harris detector 
    + https://sunshower76.github.io/cv(computervision)/2020/03/12/Feature-detector-2.-Harris-corner-detector/ 
  
# 통계학 

엔트로피 / 크로스 엔트로피
+ Cross entropy는 어떤 문제에 대해 특정 전략(확률분포)을 쓸 때 예상되는 질문개수에 대한 기댓값입니다. 
+ https://hyunw.kim/blog/2017/10/14/Entropy.html

KL divergence 콜벡 라이블러 발산 
+ KL-divergence는 p와 q의 cross entropy에서 p의 엔트로피를 뺀 값입니다. 결과적으로 두 분포의 차이를 나타냅니다.
+ https://angeloyeo.github.io/2020/10/27/KL_divergence.html

나이브 베이지안
+ 최적화 문제를 풀 때 분모의 P(B)P(B)는 결과에 영향을 미치지 않으므로 생략하거나 상수 K로 놓고 푼다 
+ https://gomguard.tistory.com/69

HMM 히든 마코프 모델
+ 한 상태(state)의 확률은 단지 그 이전 상태에만 의존한다는 것이 마코프 체인의 핵심
+ https://ratsgo.github.io/machine%20learning/2017/03/18/HMMs/


# 딥러닝 (이론&엔지니어링) 

# XAI (eXplainable AI)

