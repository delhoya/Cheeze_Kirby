
# 통계학

+ 기술 통계학 (descriptive statistics)
  + 중심:  평균
  + 산포도 : 분산 , 왜도 , 첨도
 
+ 확률과 분포 (Probability & Probability distribution)
  + 확률
  + 확률분포 (이산확률분포 , 연속확률분포)
  + 큰수의법칙 :표본평균은 모평균의 값에 수렴
  + 중심극한정리 : 모집단의 분포를 몰라도 표본평균이 어떤 분포로 수렴하는가 (정규분포)


+ 추리 통계학 (inferential statistics)
  + 모집단 (모평균 , 모표준편차)
  + 표본  (통계학 : 표본평균 , 표본표준편차)
  + 표본분포 (통계량의 확률분포 : 표본평균의 분포 / 표본비율의 분포 / 표본분산의 분포)
  + 점 추정  
  + 구간 추정
  + 가설 검증
  + 유의 수준
  
+ 귀무가설 유의성 검증
  + 귀무(Null)가설 : 아무런 영향이 없음 
  + 피셔 : 귀무가설의 유의성 검증 
  + P Value  < 0.05 : 귀무가설 기각 (귀무가설이 일어날 확률(옳다는 가능성)이 매우 적음) = 낮은 가능성에 의한 검증 (5%)
  + 유의성 검증 위험영역 : 귀무가설이 옳다 + 사건의 유의성이 일어난다 (5% 존재) 

+ 빈도주의 vs 베이즈 추론
  + 역확률 검증 -> (알고있는 경험/정보)에서 (관심 있는 사건의 확률)을 추정한다
    + https://sumniya.tistory.com/29
  + 추론 예시 : 
    + 알고 있는 정보 (질병 발병율: 0.01, 건강할 확률 0.99, 질병 걸린 사람의 양성 검출율: 0.99 , 건강한 사람의 양성 검출율 : 0.1)
    + 알고 싶은 정보 (양성 반응이 검출 되었을때 실제로 질병에 걸린 사람일 확률?)
  + 베이즈 네트워크:
    + https://blog.naver.com/PostView.nhn?isHttpsRedirect=true&blogId=jinp7&logNo=222063346933 

+ 우도
    + 주어진 데이터 vs 모델 : 예측을 얼마나 유사하게 하였나?

# 머신러닝

+ 기계학습 개론 (카이스트 문일철 교수) 
  + https://www.edwith.org/machinelearning1_17#


# 딥러닝_직무전환 교육

+ 인공지능 3주 직무전환 교육 _모두의 연구소(사내강의)
  + https://bit.ly/3hFwRcr

+ Weight & 선형함수 
  + 선형 예측하기   
  + (y = Wx+b) vs (real y) 

+ Loss function 
  + @ 예측값과 실제값의 최소 차이를 찾기 위함  
    + https://brunch.co.kr/@mnc/9 

+ Gradient descent: 
  + loss 함수의 최소값을 찾기 위한 테크닉
    + @ 미분방정식의 해를 찾기 힘들때 , 도함수의 최소값을 어떻게 계산할수 있을까? 
    + 기울기의 방향 + step size (learning rate) 를 조절하여 더듬어 찾기 가능   
    + loss function을 기울기로 업데이트 (X축 : Weight) 

+ Back propagration 
  + 미분 방정식이 여러개일때 기울기 값 영향도 분석 (?!)
    + feedforward : 순방향 전파 (y=wx+b) 
      + y = 1 / 1+e^x (.....) 비선형 함수 추가로 미분이 매우 어렵다 
      + 미분이 어려워서 비선형 함수의 학습이 어렵다가 정론이었다 
    + chain rule :
      + 전체 loss function 에 대한 각각의 delta weight 값 가중치 계산(편미분)  
      + chain rule 로 아는 변수부터 미분해가면서 연결 
    + backward : 역방향 전파 
      + https://wikidocs.net/37406
      
+ Learning rate & batch size  (@ 하이퍼파라메터)
  + 러닝레이트: 기울기 방향으로 얼마나 굴러가야하나?   
  + 배치사이즈 : 데이터를 얼마나 묶어서 써야하나?
  + 에포크 : 반복 연산 횟수 
    + @ 학습 데이터 분류 과정  
    + 배치사이즈 / 에포크 / 러닝레이트 연계
    + 배치사이즈 큼 : 큼직큼직 (모든 loss avg) vs 배치사이즈 작게 : 세세하게 보고 
    
+ Activation function 
  + 확률 변환(딥러닝초기) / 비선형성(for more deep layer) : activation 함수 
    + https://reniew.github.io/12/
    + https://dataplay.tistory.com/31

+ Logistic regression 
  + 시그모이드 함수 (0~1사이의 확률 매핑 activation)
  + 종속변수 vs 독립변수 인과관계 : 로지스틱 함수를 이용하여 추정하는 통계기법 
  + 일반적인 선형확률식 아닌 로그함수로 독립변수/종속변수 그래프로 나타낸 모델 (오즈비(성공이 될 비율) : p/1-p)
    + 지수함수로 표현가능 : e^(b0+ (b1 * x1) +....+(bn * xn))   
    + http://hleecaster.com/ml-logistic-regression-concept/ 
          
+ Loss funtion & activation function
  + MSE loss 일때 sigmoid activation 를 안쓰는 이유? (Cross entropy loss)
    + https://inhovation97.tistory.com/29  
    + https://ecsimsw.tistory.com/entry/Logistic-regression-Sigmoid-function-Cross-Entropy

+ 퍼셉트론 
  + representation
    + https://ratsgo.github.io/deep%20learning/2017/04/25/representationlearning/  
  + layer 갯수에 따라서 선형화 가능한 영역(space) 나뉨 ?!
  + 각각의 layer 에서 퍼셉트론 갯수의 의미? : 퍼셉트론을 행렬로 보자 ! (입력의 space를 차원의 조절)
  + layer 갯수의 의미? : 차원을 몇번을 바꾸겠는가? (space 공간을 몇번 바꾸겠는가?) 
    + ex 100차원 -> 10차원 한번에 하면 정보의 손실량 
    + 100차원 -> 50차원 -> 10차원 (hidden layer 갯수)   
  + 평면에서의 정보량으로는 해석이 안될때 차원을 비틀어서 해석하기 (딥러닝)  


# 딥러닝 (텐서플로우)


+ 강의 목록 (북마크 참조)
  + https://wonjun.oopy.io/70a8f11f-5728-45e8-a1a5-e6303bf56767

+ 텐서플로우 / 케라스 (사내강의)
  + https://swedu.lge.com/

+ 텐서
  + 3D(cube/voxel) 4D(array of cube/voxel) 5D(matrix of cube/voxel) 

+ 텐서 플로우 적층 구조 예시 1 (데이터 및 도메인 구조에 따른 모델 변경 학습) 

  + 입력층 (몇개의 변수를 받을거야?) (Node , perceptron) 
    + input_Layer = tf.keras.layers.Input(shape=(2,))
  
  + 히든 레이어 (Activation 사용 이유? :  비선형함수로 변환 (선형<->비선형) 
    + (ex)ReLU)
    + x1 = tf.keras.layers.Dense(4, activation='sigmoid')(input_Layer)
    + x2 = tf.keras.layers.Dense(5, activation='sigmoid')(x1)
  
  + 출력층 (Activation 사용 이유? : 출력 0~1로 변환 (Regression vs Classification) 
    + (Sigmoid/Binary entropyfor Classification) + loss function (ex) MSE for regression) 
    + Out_Layer= tf.keras.layers.Dense(1, activation='sigmoid')(x2)

  + 모델 구성
    + model = tf.keras.Model(inputs=[input_Layer], outputs=[Out_Layer])
  
  + 모델 요약
    + model.summary()

  + 레이어의 구성을 데이터에 따라서 다르게 할수 있음 (@하이퍼 파라메터)
    + ex) 자율주행 : 이미지 데이터 & 가속도 데이터 
    + https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=dlcksgod1&logNo=221140370496

+ 텐서 플로우 적층 구조 예시 2 (데이터 전처리 -  normalization)
  + Normalizaiton (데이터 전처리 과정) 
  + min max : 0~1 linear scale  (스케일 변경) 
    + (X-Xmin /  Xmax - Xmin) 
  + standardization : Zero-centered data (정규화 재배열)
    + (X-Xmean / Xstd)
    
+ 텐서 플로우 적층 구조 예시 3 (데이터 분류 (train / test split) + data 전처리 )
  + pass

+ 텐서 플로우 적층 구조 예시 4 (이진 분류 binary classification)
  + pass

+ 텐서 플로우 적층 구조 예시 4 (다중 분류 : multi classification)
  + one hot encoding (퍼셉트론의 정답을 분류)  
    + 예시 : 강아지 [1 0 0] 고양이 [0 1 0] 자동차 [0 0 1]  
    + 넘파이 : e.fit (a,b,c,d,e...) / e.transform (1,0,0....변환) 함수 사용 + to_categorical 함수 사용 
    + 판다스 : get_dummies 함수 사용 
  + softmax 함수 : e^ak / Sum(e^ak) : 퍼셉트론 확률 처럼 사용 
    + (출력층 with Activation :softmax)
    + (loss함수 : Categorical_crossEntropy 함수사용) 
    + https://hoya012.github.io/blog/anomaly-detection-overview-2/

+ EDA 자동화 라이브러리
  + https://data-newbie.tistory.com/546 
  + https://wikidocs.net/47193

+ keras 
  + .layers.Dense
  + .losses.binary_crossentropy
  + .optimizers.SGD
  + .models.Model
  + .metrics.binary_accuracy    
  + https://bskyvision.com/740
  
+ 학습테크닉 - 모델 재사용 
  + 학습이 된것을 가지고 모델 저장 완료 : 저장한 모델을 가지고 계속 시험
  + 모델 저장을 하는 함수? : model_save(name.h5)
  + 저장모델 불러와서 테스트 
  + 모델 불러오는 함수? : model_load(name.h5)
  + 모델 평가하는 함수 ? : model.evaluate()
  + 모델 재평가? / 학습 : loss 함수 + optimizer 를 바꿔서 다시 모델 학습 진행   
 
+ 학습테크닉 - 콜백 함수 (동적학습가능)
  + 훈련하는 동안 여러지점에서 콜백호출   
  + 훈련중지 , 모델저장 , 상태변경등이 가능함
  + 1. 모델 체크포인트 저장 (어떤지점일때 현재 가중치 저장)
  + 2. 조기종료 (손실이 향상없을때 훈련종료)
  + 3. 러닝레이트 스케쥴 (하이퍼파라메터 동적조정)
  

# 컴퓨터 비전

+ 의료영상처리 (DGIST 박상현 교수)
  + https://www.edwith.org/medical-20200327/joinLectures/3043

+ 영상처리 개론
  + https://www.udacity.com/

+ 웨이브릿 변환
  + https://bskyvision.com/404

+ 컴퓨터 그래픽스
  + https://m.blog.naver.com/kch8246/220713791332


# 알고리즘

+ 역량인증 강의 (사내강의)
  + http://www.codexpert.org/
  
+ 알고리즘 (유투브 강의 참조) 
  + https://colab.research.google.com/github/NoCodeProgram/CodingTest/blob/main

+ DP 문제는 제약조건이 제일 큰 힌트다 
  +  pass


# Google Collab

+ 구글 코랩 & 구글 드라이브 연동하기
  + pass 

+ 구글 코랩 (ipynb) 환경 에서 로컬(py) 파일 열기 
  + https://jlog1016.tistory.com/63 
 
+ ipynb file -> .py file 변환하기
  + https://bskyvision.com/1173

+ ipynb  <-> 깃 허브 clone / add / commit 하기
  + pass 
+ py 파일 <-> 깃 허브 clone / add / commit 하기
  + pass


# Python

+ 리스트 입력값
  + map 이용한 리스트 입력 :  list(map(int, input().split())) 
    + input / split / map / 함수로 입력 값(str->int) list 만들기
  + 속도비교 (for , map , list comprehension) 
    + https://leadsift.com/loop-map-list-comprehension/

+ 리스트 정렬
  + sort vs sorted 비교(return 차이) 
    + https://gongmeda.tistory.com/13 

+ 리스트 표현(컴프리헨션)
  + for 
    + [ save_x for (element) in range(nums)] 
      + nums 의 element를 save_x 로 저장 후 리스트  
      
    + [ save_x + 3 for element in range(nums)] 
      + save_x +3 로 저장 후 리스트 리턴
      
  + enumerate 
    + [ (idx+1,val) for idx , val in enumerate(line) ] 
      + enumerate 와 결합하여 idx , val 값 저장 후 리스트 
      
  + for  + if 문
    + [x for x in range (10,21) if x%2 ==0] 
      + 10~20 사이 x가 짝수일때 리스트 저장   
      
  + for  + if -else문
    + [ 조건 맞는 저장값 if 조건 else 조건 안맞을때 저장값 for 원소 in 반복객체 ] 
      +  [x**2 if x%2 ==1 else x **3 for x in range(1,11) ] : 나머지 조건식에 따라서 리스트 값 저장 갈라치기 가능 
  
+ 함수 입력값
  + 매개변수 초기값 설정 : *args (튜플리턴) vs **kwargs (딕셔너리 리턴) : 
    + https://velog.io/@hj8853/Python-args%EC%99%80-kwargs

+ 출력 포매팅

  + 1. % formatting : 
    + ("문자열 내 %d / %f / %s / %c"  +  %(변수명1,변수명2,변수명3...)) 
    
  + 2. {} formatting :  
    + " 문자열 내 중괄호 {},{},{}" .format(변수명1,변수명2,변수명3)  
     
  + 3. f-string formatting : 
    + f"문자열 '' 앞에 f 하나 붙이고 {변수명1} 중괄호 안에 바로 변수 사용가능 {변수명2}"
    
  + 4. dictionary formatting : 
    + "문자열 안에 {키값1}{키값2}{키값3}".format_map(딕셔너리 변수명)

+ 파이선 내장 함수

  + zip()
    + 리스트 묶어줌 : 사용예시 (data list , label list)
  + enumerate()
    + 사용예시 : 리스트 1개 인덱스 동시 출력 가능  

+ 파일 읽기 / 쓰기 open() , read() 
  + open
    + open(file_path,"w") : 파일 쓰기 
    + open(file_path,"r") : 파일 읽기 
    + open(file_path,"rb") : 바이너리 읽기
  + read 
    + read()
    + readline()
    + readlines()    
  + with as  
    + with open(file_path,mode="",encoding="") as f : 
    +   lines = f.read()
    +   print(line)    

+ 클래스
  + 클래스 변수 / 메소드 : 클래스로부터의 공통으로 활용 변수 / 기능
    + class myclass():
      + @classmethod 
      + def class_method(cls):
          + print("클래스의 메소드")  
  
  + 인스턴스 변수 / 메소드  : 각각의 인스턴스의 독자적 활용 변수 / 기능 
    + def instance_method(self):
        + self.instance_var = "인스턴스 변수"
        + print("인스턴스의 메소드")    

  + 클래스 메소드 vs 인스턴스 메소드: 
    + 인스턴스 메소드 : 인스턴스 객체 생성 후 함수 콜 가능 
    + 인스턴스 메소드 : 생성자(초기화함수) 
        + def __init__(self,init1,init2,...): 
            + self.var1 = init1
            + self.var2 = init2
  
  + 정적 메소드 :
    + https://wikidocs.net/21054
  
  + 클래스 상속 / 오버라이딩 
    + pass

  + 클래스 super() 인자 유무(범위차이)
    + https://sirzzang.github.io/dev/Dev-python-super/ 
  
+ 예외처리
  + try - except 구문 
    + try : 예외를 유발할 수 있는 구문
    +  except : 예외 처리를 수행하는 구문 
  + raise 문
    + 에러메세지 전달 (지정전달)
    + 모든 에러 BaseException의 하위클래스 :상속하여 커스텀 예외 작성 가능  
  
+ 병렬처리
  + https://yganalyst.github.io/data_handling/memo_17_parallel/
  
+ Numpy
  + dot vs matmul
    + https://blog.naver.com/cjh226/221356884894    

+ Pandas
  + iloc vs loc (인덱싱 컬럼에 문자가 들어갈수 있으니까?!)
    + https://losskatsu.github.io/programming/py-pandas-iloc/#  
  
# CS

+ 컴퓨터 
  + https://namu.wiki/w/%EC%BB%B4%ED%93%A8%ED%84%B0%20%EA%B4%80%EB%A0%A8%20%EC%A0%95%EB%B3%B4

+ 부동소수점
  + 1.23 = 123 * 10^-2 (3가지 정보가 필요)  (123 : 가수 /  2:지수 /  +- : 부호)
  + 가수: 표현 할 수있는 수의 범위  / 지수 : 정밀도 측정 
  + 예시 : 0.1 * 0.1 = 0.010000000000000002 (신경망의 연결가중치 부동소수점 문제 유의할것) 
  
+ 운영체제
  + https://www.fun-coding.org/whatisos.html 

# Linux

+ 리눅스마스터 1급
  + https://bangu4.tistory.com/category/%EC%9D%BC/Server?page=1

+ 리눅스마스터 2급
  + https://gocoder.tistory.com/1733

+ 리눅스 기본명령어
  + https://gomguard.tistory.com/73
    + cd ~ : 홈 디렉토리
    + cd .. : 상위 디렉토리
    + pwd : 현재 디렉토리
 
+ 리눅스 로그인 셀  (~ + / + . + bashrc) (명령어(~) + 절대경로(/) + 숨겨진(.) + 1파일(bashrc) 의미)
  + https://aroundck.tistory.com/6920  

+ Vimtutor
  + https://jhnyang.tistory.com/54


+ 리눅스 깃허브
  + https://woongchoi84.github.io/2020/01/15/post-productive-howtousegithub.html
 
+ 리눅스 서버 다루는 기술
  + https://thebook.io/006718/

+ 리눅스 AWS (SSH 클라이언트)
  + https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/AccessingInstancesLinux.html
  
+ 리눅스 클라우드 접속 
  + 1. Citrix 홈페이지에서 Linux용 최신 Receiver를 설치
  + 2. 인증서(AAA.pem)을 /opt/Citrix/ICAClient/Keystore/cacerts 경로에 복사
  + $ cd opt/Citrix/ICAClient/Keystore/cacerts
  + $ sudo cp ~/Downloads/AAA.pem
  + 3. /opt/Citrix/ICAClient/util/ctx_reflash 인증서정보 갱신
  + $ sudo /opt/Citrix/ICAClient/util/ctx_reflash


 
# Git

+ 깃 초기 시작 SSH-Keygen 생성
  + https://jhleed.tistory.com/166 

+ 로컬 PC <-> 깃 (clone) 
  + https://velog.io/@may-verde/%EA%B9%83%ED%97%88%EB%B8%8C%EC%97%90-%EB%A1%9C%EC%BB%AC-%ED%8F%B4%EB%8D%94-%EC%97%B0%EA%B2%B0%ED%95%98%EA%B8%B0clone 


+ 깃 버전관리 위키독스 
  + https://wikidocs.net/75554

+ 타이포라 Typora
  + https://typora.io/
  
+ 깃 기본
  + https://thewayaboutme.tistory.com/3
    
    + (branch이름) checkout : 브랜치 진입
    + clone : 가져오기
    + add . : 커밋할 목록에 추가
    + status : 상태 확인 
    + commit : 커밋 (히스토리의 단위) 만들기
    + push: 현재까지 커밋 Github 에 밀어넣기


# 분산처리 DE - 스파크 / NoSQL

+ 스파크 for 더미스 
  + https://github.com/psyoblade?tab=repositories&q=dummies&type=&language=&sort=


# 클라우드 컴퓨팅 / 가상화 

+ 생활코딩 AWS
  + https://opentutorials.org/course/2717

+ 하이퍼바이저 

+ 컨테이너 (for app easy 배포)
  + https://cloud.google.com/containers/?hl=ko

# 도커  

+ 가상머신 : 하이퍼바이저 (추가 OS) 여러개 필요 vs 도커 : 커널까지 추상화 (OS 공유) 

+ 서버 코드화의 장점
  + https://www.44bits.io/ko/post/easy-deploy-with-docker

+ 도커 실습
  + 1. 도커 만들기
    + docker create
    + ex) centos
  
  + 2. 도커 실행하기
    + docker start
    + ex) centos (docker ps 출력가능)
  
  + 3. 컨테이너 내부 실행하기 
    + docker exec (도커이름) bash /경로/실행파일 
    + docker attach 

# 웹 서비스/  프레임워크  

+ 점프 투 장고 (MVC 모델)
  + https://wikidocs.net/book/4223


# 웹 크롤링

+ https://www.fun-coding.org/crawl_basic1.html
+ bs4 
+ Selenium


# 개발능력 

+ 1. 회로설계 (Hardware) 
  + PCB (FPCB) 설계 및 SMT 
  + AutoCad / Zuken 활용 

+ 2. 펌웨어 / Build & Test (Software) 

  + Touch MCU 
  + Ti - MSP430FR2633 / FDC2214 (LG 휴대폰 Touch IC)
  + Renesase - RX230 (LG 로봇청소기) 
  + Audio MCU(DSP)
  + XMOS - Vocal fusion (Audio Beamforming / Noise Canceling)
 
+ 3. Machine learning
  + Digital Image Processing 능력 
  + Unet / Encoder_decoder  을 활용한 chest X-ray image 분리 (X-ray Dual energy - Image Segmentation) 

+ 4. Cloud / Big data

  + AWS Certification 자격증 
  + AWS 활용 (서버 엔지니어링) 
  + Docker 이용 배포 경험 
  + Big data Pipeline 구축 (hadoop / Spark )

+ 5. 기타 협업 툴 사용 
  + Linux 환경 / Git / AWS 활용 

